{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import datetime\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "from nltk.probability import FreqDist\n",
    "from string import punctuation\n",
    "from pprint import pprint\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reddit credentials\n",
    "\n",
    "reddit = praw.Reddit(client_id='bloop',\n",
    "                     client_secret='bloop',\n",
    "                     user_agent='transcipt by u/jmcnea',\n",
    "                     username='jmcnea',\n",
    "                     password='bloopbloopbloop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_subreddits = ['sandersforpresident',\n",
    "                        'elizabethwarren',\n",
    "                        'pete_buttigieg',\n",
    "                        'joebiden',\n",
    "                        'the_donald']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Comments\n",
    "\n",
    "\n",
    "with open(\"C://Users//Jordan//Documents//Word Documents//AppliedData//reddit_comments.txt\", 'w') as df:\n",
    "    \n",
    "    df.write('subreddit\\tsubmission_id\\tcomment_id\\tcomment\\tup_votes\\tdown_votes\\tusername\\tdate\\n')\n",
    "    \n",
    "    for candidate in candidates_subreddits:\n",
    "        \n",
    "        subreddit = reddit.subreddit(candidate)\n",
    "        hot_python = subreddit.hot(limit=None)\n",
    "\n",
    "        for submission in hot_python:\n",
    "            if not submission.stickied:\n",
    "\n",
    "                comments = submission.comments.replace_more(limit=None)\n",
    "\n",
    "                for idx, comment in enumerate(submission.comments.list()):\n",
    "\n",
    "                    if comment.stickied:\n",
    "                        continue\n",
    "\n",
    "                    if comment.body == '[removed]' or comment == '[deleted]':\n",
    "                        continue\n",
    "                                           \n",
    "                    \n",
    "                    \n",
    "                    # this is writing fine, but the second line looks funky.\n",
    "                    df.write(f'{candidate}\\t{submission}\\t{comment}\\t'+\n",
    "                    f'{comment.body.encode(\"utf-8\",errors=\"ignore\")}\\t{comment.ups}\\t{comment.downs}\\t{comment.author}'+\n",
    "                    f'\\t{str(datetime.datetime.fromtimestamp(comment.created))}\\n')\n",
    "\n",
    "                \n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_dict = dict()\n",
    "\n",
    "for cand in candidates_subreddits:\n",
    "    cand_dict[cand] = [0] * 10\n",
    "    cand_dict[cand][2] = ''\n",
    "    cand_dict[cand][3] = dict()\n",
    "    cand_dict[cand][4] = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
    "stopwords_sp = set(nltk.corpus.stopwords.words(\"spanish\"))\n",
    "\n",
    "def clean_list(text) :\n",
    "    ''' takes a list of text and returns a new list with \n",
    "        * words cast to lowercase\n",
    "        * stopwords removed\n",
    "        * only alphanumeric words\n",
    "    '''\n",
    "    text_clean = [w.lower() for w in text if w.isalpha()]\n",
    "    text_clean = [w for w in text_clean if w not in stopwords]\n",
    "    text_clean = [w for w in text_clean if w not in stopwords_sp]\n",
    "    return(text_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desc_features(the_description) :\n",
    "    \"\"\" Input: A twitter description\n",
    "        Output: A dictionary listin the words that are in \n",
    "                the description.\n",
    "                \n",
    "        This function does some cleaning on the descriptions,\n",
    "        removing some punctuation, splitting on whitespace, \n",
    "        dropping to lower case. It returns a dictionary \n",
    "        of the form \n",
    "            {example : True,\n",
    "             word :    True}\n",
    "    \n",
    "        \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    exclude = set(punctuation)\n",
    "    exclude.remove(\"#\") #useful for twitter...\n",
    "    \n",
    "    # Found this at https://stackoverflow.com/questions/265960/best-way-to-strip-punctuation-from-a-string-in-python\n",
    "    the_description = ''.join([ch.lower() for ch in the_description if ch not in exclude])\n",
    "    \n",
    "    word_list = the_description.split()\n",
    "\n",
    "    ret_val = {}\n",
    "    \n",
    "    for word in word_list :\n",
    "        ret_val[word] = True\n",
    "    \n",
    "    return(ret_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C://Users//Jordan//Documents//Word Documents//AppliedData//reddit_comments.txt\", 'rb') as df:\n",
    "    \n",
    "    for idx, row in enumerate(df):\n",
    "        if idx == 0:\n",
    "            continue\n",
    "        \n",
    "       \n",
    "        row = row.decode(\"utf-8\").split('\\t')\n",
    "        \n",
    "        row[3] = row[3][1:]\n",
    "        cand_dict[row[0]][2] += row[3]\n",
    "        \n",
    "        \n",
    "        row[3] = row[3].split(' ')\n",
    "        cand_dict[row[0]][0] += len(row[3])\n",
    "        cand_dict[row[0]][1] += 1\n",
    "        \n",
    "        \n",
    "        cand_words = clean_list([w.lower() for w in row[3]])\n",
    "                \n",
    "        cand_dict[row[0]][3] = desc_features(\" \".join(cand_words))\n",
    "        \n",
    "        cand_dict[row[0]][4].append(\" \".join(cand_words))\n",
    "\n",
    "        \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r/sandersforpresident summary statistics:\n",
      "total words used: 610871\n",
      "tokens used: 63930\n",
      "comments: 17872\n",
      "words per comment: 35.18\n",
      "lexical diversity: 9.56\n",
      "percent impeachment: 0.00311\n",
      "percent healthcare: 0.07956\n",
      "----------------------------------------\n",
      "r/elizabethwarren summary statistics:\n",
      "total words used: 1049757\n",
      "tokens used: 81469\n",
      "comments: 21097\n",
      "words per comment: 50.76\n",
      "lexical diversity: 12.89\n",
      "percent impeachment: 0.00572\n",
      "percent healthcare: 0.07145\n",
      "----------------------------------------\n",
      "r/pete_buttigieg summary statistics:\n",
      "total words used: 1000537\n",
      "tokens used: 87765\n",
      "comments: 25849\n",
      "words per comment: 39.71\n",
      "lexical diversity: 11.40\n",
      "percent impeachment: 0.00770\n",
      "percent healthcare: 0.03078\n",
      "----------------------------------------\n",
      "r/joebiden summary statistics:\n",
      "total words used: 252581\n",
      "tokens used: 30465\n",
      "comments: 6661\n",
      "words per comment: 38.92\n",
      "lexical diversity: 8.29\n",
      "percent impeachment: 0.00871\n",
      "percent healthcare: 0.05978\n",
      "----------------------------------------\n",
      "r/the_donald summary statistics:\n",
      "total words used: 338572\n",
      "tokens used: 51323\n",
      "comments: 16365\n",
      "words per comment: 21.69\n",
      "lexical diversity: 6.60\n",
      "percent impeachment: 0.06203\n",
      "percent healthcare: 0.00295\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for cand in cand_dict:\n",
    "    cand_words = [w.lower() for w in cand_dict[cand][2].split(' ')]\n",
    "    print(f'r/{cand} summary statistics:')\n",
    "    print(f'total words used: {len(cand_words)}')\n",
    "    print('tokens used: ' + str(len(set(cand_words))))\n",
    "    print(f'comments: {cand_dict[cand][1]}')\n",
    "    print(f'words per comment: {(cand_dict[cand][0]/cand_dict[cand][1]):.2f}')\n",
    "    print(f'lexical diversity: {(len(cand_words)/len(set(cand_words))):.2f}')\n",
    "    print('percent impeachment: '+\n",
    "          f'{(100 * cand_words.count(\"impeachment\")/len(cand_words)):.5f}')\n",
    "    print('percent healthcare: '+\n",
    "          f'{(100 * cand_words.count(\"healthcare\")/len(cand_words)):.5f}')\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r/sandersforpresident most common words: \n",
      "[('bernie', 8448), ('people', 8334), ('like', 7251), ('would', 7065), ('get', 4959), ('think', 4674), ('even', 3732), ('one', 3714), ('make', 3021), ('know', 2985), ('also', 2901), ('much', 2736), ('really', 2667), ('want', 2640), ('going', 2571), ('good', 2562), ('right', 2553), ('see', 2523), ('us', 2472), ('need', 2415), ('could', 2412), ('still', 2403), ('warren', 2343), ('sanders', 2298), ('way', 2226), ('time', 2037), ('vote', 1980), ('money', 1935), ('support', 1911), ('go', 1890), ('many', 1851), ('trump', 1809), ('say', 1794), ('pay', 1788), ('actually', 1785), ('lot', 1674), ('someone', 1659), ('better', 1626), ('take', 1599), ('new', 1554), ('sure', 1527), ('every', 1524), ('first', 1524), ('campaign', 1470), ('work', 1464), ('healthcare', 1458), ('biden', 1446), ('said', 1422), ('got', 1410), ('government', 1407)]\n",
      "****************************************\n",
      "r/elizabethwarren most common words: \n",
      "[('warren', 13893), ('would', 12487), ('people', 12304), ('like', 11908), ('think', 11819), ('get', 7613), ('bernie', 6967), ('one', 6507), ('going', 6132), ('even', 6019), ('really', 5639), ('also', 4996), ('tax', 4887), ('see', 4847), ('much', 4832), ('good', 4629), ('plan', 4595), ('make', 4495), ('want', 4325), ('need', 4204), ('way', 4004), ('still', 3907), ('know', 3880), ('go', 3794), ('pay', 3733), ('lot', 3684), ('could', 3606), ('say', 3591), ('support', 3536), ('time', 3419), ('sanders', 3398), ('actually', 3354), ('money', 3243), ('right', 3107), ('better', 3041), ('health', 2922), ('biden', 2877), ('taxes', 2846), ('wealth', 2807), ('insurance', 2758), ('take', 2743), ('candidate', 2726), ('someone', 2707), ('many', 2667), ('campaign', 2665), ('said', 2650), ('candidates', 2503), ('public', 2502), ('supporters', 2469), ('trump', 2466)]\n",
      "****************************************\n",
      "r/pete_buttigieg most common words: \n",
      "[('pete', 11964), ('like', 8494), ('people', 8220), ('think', 8120), ('would', 7136), ('one', 4848), ('get', 4700), ('really', 3932), ('also', 3688), ('even', 3594), ('see', 3504), ('know', 3468), ('good', 3404), ('going', 3386), ('warren', 3234), ('much', 2826), ('campaign', 2708), ('make', 2668), ('want', 2668), ('way', 2576), ('said', 2528), ('still', 2508), ('time', 2492), ('could', 2470), ('lot', 2424), ('buttigieg', 2398), ('say', 2294), ('candidate', 2192), ('biden', 2160), ('right', 2102), ('first', 2092), ('support', 2088), ('need', 1980), ('candidates', 1916), ('many', 1914), ('someone', 1886), ('go', 1882), ('new', 1872), ('actually', 1850), ('bernie', 1728), ('got', 1638), ('take', 1628), ('iowa', 1626), ('better', 1626), ('black', 1610), ('something', 1596), ('sure', 1566), ('trump', 1560), ('love', 1558), ('back', 1554)]\n",
      "****************************************\n",
      "r/joebiden most common words: \n",
      "[('biden', 3318), ('like', 2410), ('would', 2142), ('think', 2042), ('people', 1914), ('trump', 1378), ('joe', 1304), ('one', 1196), ('get', 1194), ('warren', 1128), ('going', 1026), ('even', 978), ('really', 942), ('bernie', 932), ('good', 886), ('see', 880), ('also', 870), ('much', 850), ('want', 830), ('support', 756), ('sanders', 730), ('vote', 692), ('make', 662), ('still', 658), ('know', 652), ('could', 642), ('way', 632), ('say', 610), ('lot', 596), ('candidate', 590), ('voters', 590), ('need', 574), ('win', 568), ('candidates', 562), ('said', 550), ('go', 548), ('harris', 528), ('actually', 526), ('better', 520), ('someone', 510), ('time', 508), ('right', 502), ('many', 502), ('left', 500), ('polls', 490), ('democratic', 488), ('far', 466), ('poll', 460), ('president', 454), ('debate', 454)]\n",
      "****************************************\n",
      "r/the_donald most common words: \n",
      "[('like', 2798), ('would', 2056), ('people', 2032), ('get', 1706), ('trump', 1628), ('one', 1532), ('think', 1442), ('even', 1338), ('know', 1314), ('see', 998), ('going', 978), ('us', 954), ('make', 914), ('got', 862), ('want', 856), ('never', 846), ('say', 832), ('need', 810), ('could', 794), ('president', 794), ('time', 776), ('heard', 776), ('really', 756), ('good', 750), ('right', 746), ('go', 734), ('fucking', 722), ('said', 720), ('still', 716), ('way', 698), ('someone', 682), ('also', 664), ('shit', 646), ('much', 632), ('every', 632), ('actually', 616), ('take', 606), ('back', 588), ('new', 546), ('guy', 538), ('first', 530), ('thing', 528), ('something', 520), ('years', 518), ('many', 516), ('left', 506), ('sure', 500), ('state', 486), ('look', 484), ('democrats', 484)]\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "for idx, cand in enumerate(cand_dict):\n",
    "    \n",
    "    cand_words = clean_list([w.lower() for w in cand_dict[cand][2].split(' ')])\n",
    "    cand_fd = FreqDist(cand_words)\n",
    "    \n",
    "    print(f'r/{cand} most common words: ')\n",
    "    print(cand_fd.most_common(50))\n",
    "    print('*'*40) \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "For Text Mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bernie vs Trump\n",
    "\n",
    "test_set_size = 5000\n",
    "\n",
    "bernieset = [(desc_features(w), 'bernie') for w in cand_dict['sandersforpresident'][4] \n",
    "            if w]\n",
    "trumpset = [(desc_features(w), 'trump') for w in cand_dict['the_donald'][4] if w]\n",
    "\n",
    "bernie_trump_set = bernieset+trumpset\n",
    "\n",
    "random.shuffle(bernie_trump_set)\n",
    "\n",
    "train_set, test_set = bernie_trump_set[test_set_size:], bernie_trump_set[:test_set_size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6894\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  bernie = True           bernie : trump  =    171.7 : 1.0\n",
      "                    pete = True           bernie : trump  =     99.8 : 1.0\n",
      "                 ukraine = True            trump : bernie =     97.1 : 1.0\n",
      "                medicare = True           bernie : trump  =     96.9 : 1.0\n",
      "                 doctors = True           bernie : trump  =     47.1 : 1.0\n",
      "                     jim = True            trump : bernie =     46.1 : 1.0\n",
      "                 sanders = True           bernie : trump  =     46.0 : 1.0\n",
      "                    iowa = True           bernie : trump  =     42.4 : 1.0\n",
      "                  jordan = True            trump : bernie =     41.6 : 1.0\n",
      "                 witness = True            trump : bernie =     40.9 : 1.0\n",
      "                  caucus = True           bernie : trump  =     38.2 : 1.0\n",
      "              healthcare = True           bernie : trump  =     35.6 : 1.0\n",
      "                   islam = True            trump : bernie =     33.4 : 1.0\n",
      "               testimony = True            trump : bernie =     32.6 : 1.0\n",
      "               ukrainian = True            trump : bernie =     28.1 : 1.0\n",
      "               insurance = True           bernie : trump  =     27.7 : 1.0\n",
      "                  donors = True           bernie : trump  =     25.8 : 1.0\n",
      "                   polls = True           bernie : trump  =     24.7 : 1.0\n",
      "                    adam = True            trump : bernie =     22.7 : 1.0\n",
      "                  hunter = True            trump : bernie =     22.7 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progressives vs Moderates\n",
    "\n",
    "test_set_size = 5000\n",
    "\n",
    "progset1 = [(desc_features(w), 'progressive') for w in cand_dict['sandersforpresident'][4] \n",
    "            if w]\n",
    "\n",
    "progset2 = [(desc_features(w), 'progressive') for w in cand_dict['elizabethwarren'][4] \n",
    "            if w]\n",
    "\n",
    "modset1 = [(desc_features(w), 'moderate') for w in cand_dict['pete_buttigieg'][4] if w]\n",
    "\n",
    "modset2 = [(desc_features(w), 'moderate') for w in cand_dict['joebiden'][4] if w]\n",
    "\n",
    "demset = progset1+progset2+modset1+modset2\n",
    "\n",
    "random.shuffle(demset)\n",
    "\n",
    "train_set, test_set = demset[test_set_size:], demset[:test_set_size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6868\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                      lj = True           modera : progre =     58.9 : 1.0\n",
      "                      aa = True           modera : progre =     27.7 : 1.0\n",
      "                cinnamon = True           modera : progre =     22.0 : 1.0\n",
      "               phonebank = True           progre : modera =     19.1 : 1.0\n",
      "                  slaves = True           progre : modera =     19.1 : 1.0\n",
      "                     vat = True           progre : modera =     18.8 : 1.0\n",
      "             submissions = True           progre : modera =     18.6 : 1.0\n",
      "                  busing = True           modera : progre =     18.0 : 1.0\n",
      "                 mayoral = True           modera : progre =     16.6 : 1.0\n",
      "                      sb = True           modera : progre =     15.4 : 1.0\n",
      "                bolivian = True           progre : modera =     15.2 : 1.0\n",
      "                 bullock = True           modera : progre =     14.9 : 1.0\n",
      "             celebration = True           modera : progre =     14.8 : 1.0\n",
      "               loopholes = True           progre : modera =     14.8 : 1.0\n",
      "                   fraud = True           progre : modera =     14.7 : 1.0\n",
      "                   jason = True           modera : progre =     14.2 : 1.0\n",
      "               newspaper = True           modera : progre =     14.0 : 1.0\n",
      "                  greedy = True           progre : modera =     13.6 : 1.0\n",
      "             capitalists = True           progre : modera =     13.6 : 1.0\n",
      "                     oas = True           progre : modera =     13.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Democrats vs Trump\n",
    "\n",
    "test_set_size = 5000\n",
    "\n",
    "demset1 = [(desc_features(w), 'democrat') for w in cand_dict['sandersforpresident'][4] if w]\n",
    "\n",
    "demset2 = [(desc_features(w), 'democrat') for w in cand_dict['elizabethwarren'][4] if w]\n",
    "\n",
    "demset3 = [(desc_features(w), 'democrat') for w in cand_dict['pete_buttigieg'][4] if w]\n",
    "\n",
    "demset4 = [(desc_features(w), 'democrat') for w in cand_dict['joebiden'][4] if w]\n",
    "\n",
    "trumpset = [(desc_features(w), 'trump') for w in cand_dict['the_donald'][4] if w]\n",
    "\n",
    "totalset = demset1+demset2+demset3+demset4+trumpset\n",
    "\n",
    "\n",
    "random.shuffle(totalset)\n",
    "\n",
    "train_set, test_set = totalset[test_set_size:], totalset[:test_set_size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8482\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    pete = True           democr : trump  =    751.4 : 1.0\n",
      "                   islam = True            trump : democr =    155.5 : 1.0\n",
      "                  jordan = True            trump : democr =    133.9 : 1.0\n",
      "                 hearsay = True            trump : democr =    131.9 : 1.0\n",
      "                  bernie = True           democr : trump  =    120.4 : 1.0\n",
      "                  drudge = True            trump : democr =    118.5 : 1.0\n",
      "                  taylor = True            trump : democr =    103.1 : 1.0\n",
      "                     tds = True            trump : democr =     78.5 : 1.0\n",
      "                    iowa = True           democr : trump  =     67.4 : 1.0\n",
      "             bureaucrats = True            trump : democr =     60.0 : 1.0\n",
      "                medicare = True           democr : trump  =     56.8 : 1.0\n",
      "               witnesses = True            trump : democr =     51.8 : 1.0\n",
      "                   mints = True            trump : democr =     50.8 : 1.0\n",
      "                  drumpf = True            trump : democr =     47.7 : 1.0\n",
      "                 sanders = True           democr : trump  =     46.2 : 1.0\n",
      "                  warren = True           democr : trump  =     45.1 : 1.0\n",
      "                     liz = True           democr : trump  =     44.8 : 1.0\n",
      "                    hoax = True            trump : democr =     44.6 : 1.0\n",
      "               diplomats = True            trump : democr =     44.6 : 1.0\n",
      "                    beto = True           democr : trump  =     41.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bernie vs Warren\n",
    "\n",
    "test_set_size = 5000\n",
    "\n",
    "bernieset = [(desc_features(w), 'bernie') for w in cand_dict['sandersforpresident'][4] if w]\n",
    "\n",
    "warrenset = [(desc_features(w), 'warren') for w in cand_dict['elizabethwarren'][4] if w]\n",
    "\n",
    "totalset = bernieset+warrenset\n",
    "\n",
    "\n",
    "random.shuffle(totalset)\n",
    "\n",
    "train_set, test_set = totalset[test_set_size:], totalset[:test_set_size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6002\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 slavery = True           bernie : warren =     30.0 : 1.0\n",
      "                    rand = True           bernie : warren =     26.1 : 1.0\n",
      "                behavior = True           warren : bernie =     24.1 : 1.0\n",
      "                    bite = True           warren : bernie =     23.6 : 1.0\n",
      "                    lula = True           bernie : warren =     22.6 : 1.0\n",
      "                     evo = True           bernie : warren =     21.7 : 1.0\n",
      "                     cia = True           bernie : warren =     19.3 : 1.0\n",
      "                   slave = True           bernie : warren =     18.5 : 1.0\n",
      "                  empire = True           bernie : warren =     18.5 : 1.0\n",
      "               phonebank = True           bernie : warren =     17.5 : 1.0\n",
      "                 spanish = True           bernie : warren =     16.7 : 1.0\n",
      "                 handled = True           warren : bernie =     16.0 : 1.0\n",
      "                  slaves = True           bernie : warren =     13.5 : 1.0\n",
      "              zuckerberg = True           warren : bernie =     13.2 : 1.0\n",
      "               economist = True           warren : bernie =     13.2 : 1.0\n",
      "                     ice = True           bernie : warren =     13.0 : 1.0\n",
      "                     liz = True           warren : bernie =     12.9 : 1.0\n",
      "                    jews = True           bernie : warren =     12.7 : 1.0\n",
      "                     vat = True           warren : bernie =     12.7 : 1.0\n",
      "                  abrams = True           warren : bernie =     12.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaining: \n",
    "# Warren vs Trump\n",
    "\n",
    "test_set_size = 5000\n",
    "\n",
    "warrenset = [(desc_features(w), 'warren') for w in cand_dict['elizabethwarren'][4] if w]\n",
    "\n",
    "trumpset = [(desc_features(w), 'trump') for w in cand_dict['the_donald'][4] if w]\n",
    "\n",
    "totalset = warrenset+trumpset\n",
    "\n",
    "\n",
    "random.shuffle(totalset)\n",
    "\n",
    "train_set, test_set = totalset[test_set_size:], totalset[:test_set_size]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6746\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    pete = True           warren : trump  =    255.9 : 1.0\n",
      "                  bernie = True           warren : trump  =    129.1 : 1.0\n",
      "                medicare = True           warren : trump  =    124.9 : 1.0\n",
      "                     liz = True           warren : trump  =    107.8 : 1.0\n",
      "                  jordan = True            trump : warren =     86.1 : 1.0\n",
      "                  warren = True           warren : trump  =     86.0 : 1.0\n",
      "                   polls = True           warren : trump  =     79.2 : 1.0\n",
      "                 sanders = True           warren : trump  =     70.6 : 1.0\n",
      "                   plans = True           warren : trump  =     59.9 : 1.0\n",
      "              candidates = True           warren : trump  =     55.0 : 1.0\n",
      "                   costs = True           warren : trump  =     53.3 : 1.0\n",
      "                 endorse = True           warren : trump  =     48.0 : 1.0\n",
      "                 doctors = True           warren : trump  =     47.0 : 1.0\n",
      "              healthcare = True           warren : trump  =     46.9 : 1.0\n",
      "                 epstein = True            trump : warren =     46.7 : 1.0\n",
      "                  donors = True           warren : trump  =     45.6 : 1.0\n",
      "                    beto = True           warren : trump  =     41.2 : 1.0\n",
      "                trillion = True           warren : trump  =     40.8 : 1.0\n",
      "                   tulsi = True           warren : trump  =     40.8 : 1.0\n",
      "               insurance = True           warren : trump  =     39.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
